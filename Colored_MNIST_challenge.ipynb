{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "MNIST Challenge 2024-10-19\n",
        "You have three test datasets corresponding to three difficulties, easy, medium and hard. The objective of this challenge is to learn how to make an effective model and intelligent data processing to classify accuretaly MNIST images even if they are degraded. The higher the difficulty, the more degraded the test images are. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHMcZCq9wM12"
      },
      "source": [
        "We download two libraries that aren't automatically on colab's environment :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OLDntfLkwo7R",
        "outputId": "cc90b21c-3602-478f-bda7-8a9d7a299898"
      },
      "outputs": [],
      "source": [
        "!pip install torchinfo\n",
        "!pip install gdown"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JDLxiEFy1y7M"
      },
      "source": [
        "\n",
        "We import the libraries :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "81SFiCGZwM14"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from torchinfo import summary\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "import gzip\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HoGmBBFw18Ds"
      },
      "source": [
        "Here we download the datasets from Google Drive : (https://drive.google.com/drive/folders/1tgwAUkoPU1DwoUs_mTa9ZvGJ0cIhY3ob)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Ooqv2sIxFk_",
        "outputId": "0c2caf57-91df-46f1-bf62-e3406e7433f9"
      },
      "outputs": [],
      "source": [
        "!gdown 1BppDIfS3QqmnAz-ZZzoJ19rwFwetaH17\n",
        "!gdown 1o5Xa6nmiNYgFuoGTYCRYXKKKUkV3bxJL\n",
        "!gdown 1ojvAvkjDMruiY-q6Ev8LDDDPpOn1gcYT\n",
        "!gdown 1ho4_rFWJ4MZMzyHdm_qlgStm2eGFuQDq\n",
        "!gdown 1n8iIzBxaWeLRahQkKhs1dkuBfSm8INbN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pO3zJqDTwM16"
      },
      "source": [
        "Unzip the files :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "25tD8ItywM16"
      },
      "outputs": [],
      "source": [
        "# Function to load data from a .gz file\n",
        "def load_from_gz(filename):\n",
        "    with gzip.open(filename, 'rb') as f:\n",
        "        data = pickle.load(f)\n",
        "    return data\n",
        "\n",
        "# Load the data\n",
        "loaded_images = load_from_gz('colored_mnist_images.gz')\n",
        "loaded_targets = load_from_gz('colored_mnist_targets.gz')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qtO81sgIwM17"
      },
      "source": [
        "Create the dataset and the dataloader :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TDKSxE3TwM17"
      },
      "outputs": [],
      "source": [
        "\n",
        "class ColoredMNISTDataset(Dataset):\n",
        "    def __init__(self, images, targets):\n",
        "        self.images = images\n",
        "        self.targets = targets\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.targets)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = self.images[idx]\n",
        "        target = self.targets[idx]\n",
        "        return torch.tensor(image), target\n",
        "\n",
        "# Create the dataset\n",
        "train_dataset = ColoredMNISTDataset(loaded_images, loaded_targets)\n",
        "\n",
        "# Create a DataLoader for the dataset\n",
        "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=..., shuffle=True)\n",
        "#You can change the batch_size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQxkX9xbwM17"
      },
      "source": [
        "Show some images and their labels :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 473
        },
        "id": "KtTfIIZLwM17",
        "outputId": "d87286cf-2a77-4e25-9d46-9766613119d0"
      },
      "outputs": [],
      "source": [
        "# Function to show an image\n",
        "def imshow(img):\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    #the transpose allow the image to be in the good shape for plt.imshow\n",
        "    plt.show()\n",
        "\n",
        "# Get some training images\n",
        "images, labels = next(iter(train_dataloader))\n",
        "\n",
        "# Show images\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "\n",
        "# Print labels\n",
        "print(' '.join('%5s' % labels[j].item() for j in range(8)))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ry33dEQkwM17"
      },
      "source": [
        "Create your model here. Consider looking at pytorch documentation. You can also use CNN for instance. Pretrained models are forbidden. Here is an example of a model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D6Nl3_10wM17",
        "outputId": "289fb776-50a2-4fe5-dcf6-299b6d02568b"
      },
      "outputs": [],
      "source": [
        "# model goes here\n",
        "model = ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVAPqslqwM19"
      },
      "source": [
        "Define your loss and your optimizer. Consider testing different losses."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4HThVmB2wM19"
      },
      "outputs": [],
      "source": [
        "criterion = ...\n",
        "optimizer = ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WMTSGxmHwM19"
      },
      "source": [
        "The training loop :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aSS36SbIwM19",
        "outputId": "45f91c40-f433-49cc-fc22-830f300dd116"
      },
      "outputs": [],
      "source": [
        "num_epochs = ...\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    running_loss = 0.0\n",
        "    for inputs, labels in tqdm(train_dataloader):\n",
        "        # to complete\n",
        "        ...\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define your accuracy measurement here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def accuracy(dataset, model):\n",
        "    ...\n",
        "\n",
        "accuracy(train_dataloader, model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-JDT587wM19"
      },
      "source": [
        "Then you create your testset. Here, you have to create another class than the one used for the training set because of course you don't have access to the labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e_9Y_-gywM19"
      },
      "outputs": [],
      "source": [
        "#change the difficulty by replacing \"easy\" by \"medium\" or \"hard\"\n",
        "loaded_test_images = load_from_gz('colored_mnist_test_images_easy.gz')\n",
        "\n",
        "class TestMNISTDataset(Dataset):\n",
        "    def __init__(self, images):\n",
        "        self.images = images\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = self.images[idx]\n",
        "        return torch.tensor(image)\n",
        "\n",
        "# Create the new dataset\n",
        "test_dataset = TestMNISTDataset(loaded_test_images)\n",
        "\n",
        "# Create a DataLoader for the new dataset\n",
        "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=..., shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Schy6BamwM19"
      },
      "source": [
        "Then in order to get your model's accuracy you have to create your predictions.npy file and to upload this file on CS sharing (according to the difficulty you've chosen)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5BrnDjp1wM19"
      },
      "outputs": [],
      "source": [
        "\n",
        "predictions=[]\n",
        "\n",
        "for img in test_dataloader :\n",
        "    img = img.to(device)\n",
        "    l=np.array(model(img.float()).tolist())\n",
        "    predicted=[]\n",
        "    for i in range(len(l)) :\n",
        "        predicted.append(np.argmax(l[i]))\n",
        "    predictions.extend(predicted)\n",
        "\n",
        "\n",
        "\n",
        "np.save('predictions.npy', predictions)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
